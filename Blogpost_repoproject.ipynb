{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "The goal of this project was to recreate the neural network and the results (partly) of the following paper: Estimating individual treatment effect: generalization bounds and algorithms (Uri Shalit et al.). The autors of this paper aim to predict the indiviudel treatment effect (ITE) from observational data. Therefore they propose a CFR (Counterfactual Regression) framework. In addition, the authors used a Tensorflow framework for the creating of their network. In this project we aim to reconstruct their network in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Individual treatment effect\n",
    "The invidual treatment effect (ITE) can be seen as the effect of a certain treatment for a specific patient. One can imagine that it is very usefull to estimate the outcome of a given treatment before the patient receive the treatment.A doctor could then choose the treatment based on the estimated outcome. Observational data e.g. given medication is used order to make such predictions. The ITE can be calculated using the following formula:\n",
    "\n",
    "$$ITE (x) = E[Y_1 - Y_0 | x]$$\n",
    "\n",
    "Where $$Y_1$$ is the outcome given the treatment and $$Y_0$$ the outcome not given the treatment. Then the ITE of a certain treatment is then the expected outcome given the treatment minus the expected outcome not given the treatment when observing data x."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IHDP dataset\n",
    "This project makes use of the IHDP (Infant Health and Development Program) dataset, in this dataset consist of data from early born baby's and their mother. It includes data of 747 patients from whom 25 covariantes (x) where measured for a total of 100 treatments.\n",
    "\n",
    "![Table](img/Flowdiagram_repo_projec_Page-3.png)\n",
    "\n",
    "This table shows the structure of the dataset.\n",
    "The value t {1,0} indicates wether a patient is treated (1) or not (0), the y_factual is the outcome and the yc_factual is the outcome if one would have give the opposite treatment. This for example: if a diabetic patient received an insuline in treatment the t value would be 1 for the insuline treatment and the y_factual would be the \"factual\" outcome, the yc_factual outcome would then be the outcome given the opposite treatmentm, so when no insuline was given."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CFR-net\n",
    "For the recreating of the CFR network we firstly stepwise unrevaled the Tensorflow code made by the authors. For this purpose we created a flowchart to gain insight in the proposed network:\n",
    "![Flowchart](img/Flowdiagram_repo_projec_Page-2.png)\n",
    "\n",
    "It can be seen that the network consist of 6 layers, the ReLU a non-linear activation, uses mutiple dropout layers and at half-way it concatenates with the t-values. Finally it gives an output vector y (factual)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FCNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple fully connected neural network with residual connections in PyTorch.\n",
    "    Layers are defined in __init__ and forward pass implemented in forward.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FCNet, self).__init__()\n",
    "\n",
    "        p = 0.4\n",
    "\n",
    "        self.h_in = nn.Linear(25, 100)\n",
    "        self.layer_1 = nn.Linear(100, 100)\n",
    "        self.layer_2 = nn.Linear(100, 100)\n",
    "        self.layer_3 = nn.Linear(101, 100)\n",
    "        self.layer_4 = nn.Linear(100, 100)\n",
    "        self.layer_5 = nn.Linear(100, 100)\n",
    "\n",
    "        self.do1 = torch.nn.Dropout(p=p)\n",
    "        self.do2 = torch.nn.Dropout(p=p)\n",
    "        self.do3 = torch.nn.Dropout(p=p)\n",
    "        self.do4 = torch.nn.Dropout(p=p)\n",
    "        self.do5 = torch.nn.Dropout(p=p)\n",
    "        self.do6 = torch.nn.Dropout(p=p)\n",
    "        self.fc6 = nn.Linear(100,1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        h = self.do1(F.relu(self.h_in(x)))\n",
    "        h = self.do2(F.relu(self.layer_1(h)))\n",
    "        h_rep = self.do3(F.relu(self.layer_2(h)))\n",
    "        h = self._build_output_graph( h, t)\n",
    "\n",
    "        return h, h_rep\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training loop\n",
    "The training loop of the CFR network makes use of a ADAM optimizer and a MSE-loss criterion. The data set was splitted into 75 test samples and 672 train samples. A total of 2000 epochs was used for training.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corrections for distribution difference\n",
    "To compensate for the difference in group size (treated / non treated) a sample re-weighting was introduced. All the samples were re-weighted with the following formula:\n",
    "\n",
    "$$wi = \\frac{ti}{2u} + \\frac{1-ti}{2(1-u)}$$ for $$i = 1 ... n $$\n",
    "\n",
    "With t {1,0} and u, the treatment prediction i.e. the chance of being treated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Sample reweighting\n",
    "    if flags.get_val('reweight_sample'):\n",
    "        w_t = t / (2 * p_t)\n",
    "        w_c = (1 - t) / (2 * 1 - p_t)\n",
    "        sample_weight = w_t + w_c\n",
    "    else:\n",
    "        sample_weight = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to the re-weighting of the samples an imbalance error was introduced in the loss function. The imbalnce error adjusts for the bias induced by the treatment group imbalance. There are different methods for the calculation of the imbalance error. For this project the squared linear Maximum Mean discrepancy (MMD) and the Wasserstein methods were used. The actual computations of these imbalance errors goes a bit beyond the scope of this blog post. However, it is good to know that there was corected for the distribution imbalance in two differnt ways. This will also result in two different outcomes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outcome measures\n",
    "--> PEHE\n",
    "--> ATE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}